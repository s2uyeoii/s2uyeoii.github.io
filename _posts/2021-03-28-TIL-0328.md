---
layout: post
title: TIL/0328
subtitle: 빅데이터처리
comments: true
tags: [TIL]
category: [TIL]
---
**오늘 공부 및  일 리스트**

 - [x] 빅데이터처리 강의 수강 및 과제 
 - [x] c언어 강의 수강 및 문제풀이

## 빅데이터처리
### 피보나치 수열을 파이썬으로 표현
: 값을 입력받아(n) n번째 항의 피보나치 값을 구현

    n = int(input("몇번째 항의 값 구할것인지 입력:" ))
    fibo = list(0 for i in range(0,n))
    #print(fibo)
    for k in range(0,n):
        if(k==0 or k==1):
            fibo.insert(k,1)
        else:
            fibo[k] = fibo[k-1] + fibo[k-2]
    print('{0}번째 항: {1}'.format(n, fibo[n-1]))
    
<code>실행 결과:</code> 

    몇번째 항의 값 구할것인지 입력:40
    40번째 항: 102334155 
    
<br>


### 하둡과 하둡에코시스템을 내 말로 표현?
하둡은 방대한 양의 빅데이터가 들어오면 그 데이터 파일을 쪼개서 여러대의 컴퓨터가 나누어서 처리하도록 한다. 데이터를 잃어버리는 것을 대비해 데이터는 여러 대의 컴퓨터에 중복 저장한다. 그 다음 데이터가 저장된 컴퓨터에서 데이터를 분석하고 그 결과를 합친다. 또 비용의 낭비를 방지하기 위해 전원이 꺼져도 인터넷 상에 처리된 데이터가 저장되어 있을 수 있도록 하는 클라우드 컴퓨팅 기술을 지원한다. 하둡 에코 시스템은 분산 프로그래밍을 지원하는 하둡의 구조(프레임워크)를 이루고 있는 다양한 서브 프로젝트의 모임이다. 코어 프로젝트 중 분산시스템인 hdfs에 데이터를 저장하고 맵리듀스를 이용해 데이터를 처리한다. 나머지(zookeeper, hbase, sqoop, pig 등)은 데이터 마이닝, 수집, 분석등을 수행한다. 그 나머지 중 Sqoop은 관계형 데이터베이스와 하둡 HDFS간에 데이터를 전송할 수 있도록 설계된 오픈소스 소프트웨어이다.

다음으로 flume은 지정한 모든 서버로부터 로그를 수집한 후 하둡 hdfs 같은 중앙 저장소에 데이털를 로드하고 분석하는 시스템을 구축하는 것을 돕는다. 다음으로 pig는 큰 돼지처럼 대용량의 데이터셋을 조금 더 잘 처리할 수 있게 해준다. 하이브는 하둡 에코시스템 중에서 데이터를 모델링하고 프로세싱하는 경우 가장 많이 사용하는 솔루션이다. Oozie는 하둡의 작업들을 스케줄링하는 코디네이터 역할을 한다. Zookeeper 은 사육사 아이콘으로 빅데이터의 벌(hive), 코끼리(하둡), 범고래(hbase)등을 관리하는 사육사의 역할로서 이름을 그렇게 정했다고 한다. 실제로 zookeeper은 하둡의 많은 분산 처리 프로그램의 코디네이터 기능을 하고 있다. 주키퍼는 특히 ‘부분 실패’를 처리하는데, 부분 실패란 다음과 같다. 메세지를 전송하고 네트워크가 끊겼을 때 송신자는 수신자가 메세지를 성공적으로 수신했는지 조차 알 수 없게 된다. 어쩌면 메시지를 받고 처리를 하고 나서 응답을 못준 것일 수도 있고, 메세지 전송 자체가 실패된 것일 수도 있다. 작업이 성공한 것인지 실패한 것인지 여부조차 알 수 없는 것이다.

주키퍼는 이러한 부분 실패를 안전하게 처리하기 위한 분산 처리 도구를 제공한다.
