---
layout: post
title: TIL/0405
subtitle: 
comments: true
tags: [TIL, 빅데이터처리, hadoop, 교육심리]
category: [TIL]

---
**오늘 공부 및  일 리스트**

 - [x] 빅데이터처리 과제
 - [x] 운영체제(스케줄링) 공부, 기출 풀이

## 빅데이터처리

**하둡이란?**

:  하둡은 대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈소스 프레임워크로 2005년에 더그 커팅이 구글이 논문으로 발표한 GFS(Google File System)와 맵리듀스를 구현한 결과물이다.

더그 커팅이 자신의 아들이 노란 코끼리 장난감 인형을 하둡이라고 부르는 것을 듣고 하둡이라는 이름을 지었으며, 이 때문에 하둡의 로고로 노란 코끼리가 사용된다. 이러한 프로젝트 네이밍 룰 때문에 이후 하둡 관련 서브 프로젝트(zookeeper, hbase, pig 등등)도 모두 동물과 관련된 이름을 사용한다.

하둡은 처음에는 오픈소스 검색 엔진인 너치에 적용하기 위해 시작됐다가 이후 독립적인 프로젝트로 만들어졌고, 2008년에는 아파치 최상위 프로젝트로 승격되었다. 하둡은 분산 파일 시스템인 HDFS(Hadoop Distributed File System)에 데이터를 저장하고, 분산 처리 시스템인 맵리듀스를 이용해 데이터를 처리한다.

하둡은 방대한 양의 빅데이터가 들어오면 그 데이터 파일을 쪼개서 여러대의 컴퓨터가 나누어서 처리하도록 한다. 데이터를 잃어버리는 것을 대비해 데이터는 여러 대의 컴퓨터에 중복 저장한다. 그 다음 데이터가 저장된 컴퓨터에서 데이터를 분석하고 그 결과를 합친다. 또 비용의 낭비를 방지하기 위해 전원이 꺼져도 인터넷 상에 처리된 데이터가 저장되어 있을 수 있도록 하는 클라우드 컴퓨팅 기술을 지원한다.

하둡 에코 시스템은 분산 프로그래밍을 지원하는 하둡의 구조(프레임워크)를 이루고 있는 다양한 서브 프로젝트의 모임이다. 코어 프로젝트 중 분산시스템인 hdfs에 데이터를 저장하고 맵리듀스를 이용해 데이터를 처리한다. 나머지(zookeeper, hbase, sqoop, pig 등)은 데이터 마이닝, 수집, 분석등을 수행한다.

그 나머지 중 Sqoop은 관계형 데이터베이스와 하둡 HDFS간에 데이터를 전송할 수 있도록 설계된 오픈소스 소프트웨어이다. 다음으로 flume은 지정한 모든 서버로부터 로그를 수집한 후 하둡 hdfs 같은 중앙 저장소에 데이털를 로드하고 분석하는 시스템을 구축하는 것을 돕는다. 다음으로 pig는 큰 돼지처럼 대용량의 데이터셋을 조금 더 잘 처리할 수 있게 해준다. 하이브는 하둡 에코시스템 중에서 데이터를 모델링하고 프로세싱하는 경우 가장 많이 사용하는 솔루션이다. Oozie는 하둡의 작업들을 스케줄링하는 코디네이터 역할을 한다. Zookeeper 은 사육사 아이콘으로 빅데이터의 벌(hive), 코끼리(하둡), 범고래(hbase)등을 관리하는 사육사의 역할로서 이름을 그렇게 정했다고 한다. 실제로 zookeeper은 하둡의 많은 분산 처리 프로그램의 코디네이터 기능을 하고 있다. 주키퍼는 특히 ‘부분 실패’를 처리하는데, 부분 실패란 다음과 같다. 메세지를 전송하고 네트워크가 끊겼을 때 송신자는 수신자가 메세지를 성공적으로 수신했는지 조차 알 수 없게 된다. 어쩌면 메시지를 받고 처리를 하고 나서 응답을 못준 것일 수도 있고, 메세지 전송 자체가 실패된 것일 수도 있다. 작업이 성공한 것인지 실패한 것인지 여부조차 알 수 없는 것이다. 즉, 주키퍼는 이러한 부분 실패를 안전하게 처리하기 위한 분산 처리 도구를 제공한다.
